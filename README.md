**ğŸ“Š Sentiment Analysis: Model Comparison**

**Author: Deekshitha Chowdary Kalluri**

**Course: CIS 732 â€“ Machine Learning (Term Project)**

**ğŸ“‚ Included Files**

- SentimentClassification.ipynb â€” Jupyter notebook for model training, evaluation, and visualization

- FINAL REPORT.pdf â€” Detailed report with methodology, results, and analysis

- FINAL PPT.pptx â€” Summary presentation slides

- IMDB Dataset.csv â€” Preprocessed, balanced IMDb movie review dataset (2,500 samples)

- README.md â€” Project overview and submission details

**ğŸ“ Project Summary**

This project evaluates and compares the performance of four sentiment classification models on a curated IMDb movie review dataset:

- Logistic Regression

- Linear Support Vector Classifier (LinearSVC)

- Long Short-Term Memory (LSTM)

- BERT (Bidirectional Encoder Representations from Transformers)


All models were trained on binary-labeled data (positive vs. negative), with standardized preprocessing and evaluation using:

- Accuracy

- F1 Score

- AUC-ROC

- Confusion Matrix


**ğŸ” Key Findings**
**âœ… Classical Models**

- Logistic Regression

  - Accuracy: 0.842

  - F1 Score: 0.8448

  - AUC-ROC: 0.9256

- LinearSVC

  - Accuracy: 0.850

  - F1 Score: 0.8497

  - AUC-ROC: 0.9254

  - Performed best among classical methods


**ğŸ” LSTM Model**

- Struggled due to limited data and vocabulary

- Accuracy: 0.50, F1 Score: 0.0602

- Severe underfitting observed


**ğŸ¤– Transformer Model (BERT)**

- Pretrained BERT (no fine-tuning)

  - Accuracy: 0.496, F1 Score: 0.6471

  - Poor balance in classification

- Fine-Tuned BERT

  - Accuracy: 0.932, F1 Score: 0.9308, AUC-ROC: 0.977

  - Outperformed all other models


**ğŸ“ˆ Statistical Analysis**

Paired t-tests were conducted comparing fine-tuned BERT against baseline models. While BERT achieved the best metrics, no statistically significant differences were found due to sample size limitations.


**ğŸ“Œ Conclusion**

- LinearSVC is a strong classical baseline for small datasets

- Fine-tuned BERT achieves the best overall performance

- LSTM and unfine-tuned BERT models underperformed in this scenario

- Statistical validation is critical when working with small datasets


**ğŸ”® Future Work**

- Use larger datasets

- Experiment with RoBERTa, DistilBERT, or LoRA adapters

- Tune hyperparameters and training epochs

- Explore prompt engineering for transformer models


**ğŸ”— Project Repository: https://github.com/DeekshithaKalluri/SentimentAnalysis**
